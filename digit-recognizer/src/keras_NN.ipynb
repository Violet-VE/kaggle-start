{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train = pd.read_csv('../input/train.csv')\n",
    "    test = pd.read_csv('../input/test.csv')\n",
    "    print(\"train shape:{}\\ntest shape:{}\".format(train.shape, test.shape))\n",
    "    \n",
    "    train_df = train.drop(['label'], axis=1)\n",
    "    label = pd.get_dummies(train['label'])\n",
    "    #train_df = train_df/255.0\n",
    "    #test = test/255.0\n",
    "    train_df = train_df.applymap(lambda x: x/255).astype(np.float32)\n",
    "    test = test.applymap(lambda x: x/255).astype(np.float32)\n",
    "    \n",
    "    # Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "    train_df = train_df.values.reshape(-1,28,28,1)\n",
    "    test = test.values.reshape(-1,28,28,1)\n",
    "    \n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(train_df, label, test_size=0.2, random_state=2017)\n",
    "    print(\"x_train shape:\"+str(x_train.shape))\n",
    "    print(\"x_valid shape:\"+str(x_valid.shape))\n",
    "    \n",
    "    return x_train, y_train, x_valid, y_valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:(42000, 785)\n",
      "test shape:(28000, 784)\n",
      "x_train shape:(33600, 28, 28, 1)\n",
      "x_valid shape:(8400, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/50\n",
      "33600/33600 [==============================] - 13s 396us/step - loss: 0.8678 - acc: 0.7172 - val_loss: 0.1705 - val_acc: 0.9485\n",
      "Epoch 2/50\n",
      "33600/33600 [==============================] - 12s 368us/step - loss: 0.2728 - acc: 0.9214 - val_loss: 0.1032 - val_acc: 0.9687\n",
      "Epoch 3/50\n",
      "33600/33600 [==============================] - 12s 360us/step - loss: 0.1954 - acc: 0.9455 - val_loss: 0.0822 - val_acc: 0.9745\n",
      "Epoch 4/50\n",
      "33600/33600 [==============================] - 13s 380us/step - loss: 0.1519 - acc: 0.9584 - val_loss: 0.0683 - val_acc: 0.9783\n",
      "Epoch 5/50\n",
      "33600/33600 [==============================] - 12s 369us/step - loss: 0.1265 - acc: 0.9654 - val_loss: 0.0590 - val_acc: 0.9825\n",
      "Epoch 6/50\n",
      "33600/33600 [==============================] - 13s 382us/step - loss: 0.1095 - acc: 0.9691 - val_loss: 0.0586 - val_acc: 0.9823\n",
      "Epoch 7/50\n",
      "33600/33600 [==============================] - 12s 367us/step - loss: 0.0934 - acc: 0.9745 - val_loss: 0.0466 - val_acc: 0.9857\n",
      "Epoch 8/50\n",
      "33600/33600 [==============================] - 13s 384us/step - loss: 0.0832 - acc: 0.9772 - val_loss: 0.0481 - val_acc: 0.9870\n",
      "Epoch 9/50\n",
      "33600/33600 [==============================] - 12s 371us/step - loss: 0.0765 - acc: 0.9780 - val_loss: 0.0469 - val_acc: 0.9871\n",
      "Epoch 10/50\n",
      "33600/33600 [==============================] - 12s 367us/step - loss: 0.0693 - acc: 0.9816 - val_loss: 0.0387 - val_acc: 0.9893\n",
      "Epoch 11/50\n",
      "33600/33600 [==============================] - 12s 367us/step - loss: 0.0644 - acc: 0.9823 - val_loss: 0.0409 - val_acc: 0.9881\n",
      "Epoch 12/50\n",
      "33600/33600 [==============================] - 12s 370us/step - loss: 0.0561 - acc: 0.9847 - val_loss: 0.0422 - val_acc: 0.9895\n",
      "Epoch 13/50\n",
      "33600/33600 [==============================] - 12s 367us/step - loss: 0.0537 - acc: 0.9851 - val_loss: 0.0394 - val_acc: 0.9894\n",
      "Epoch 14/50\n",
      "33600/33600 [==============================] - 12s 369us/step - loss: 0.0474 - acc: 0.9864 - val_loss: 0.0392 - val_acc: 0.9902\n",
      "Epoch 15/50\n",
      "33600/33600 [==============================] - 12s 368us/step - loss: 0.0437 - acc: 0.9887 - val_loss: 0.0372 - val_acc: 0.9912\n",
      "Epoch 16/50\n",
      "33600/33600 [==============================] - 12s 368us/step - loss: 0.0433 - acc: 0.9874 - val_loss: 0.0386 - val_acc: 0.9905\n",
      "Epoch 17/50\n",
      "33600/33600 [==============================] - 12s 370us/step - loss: 0.0387 - acc: 0.9893 - val_loss: 0.0377 - val_acc: 0.9904\n",
      "Epoch 18/50\n",
      "33600/33600 [==============================] - 12s 366us/step - loss: 0.0343 - acc: 0.9907 - val_loss: 0.0392 - val_acc: 0.9901\n",
      "Epoch 19/50\n",
      "33600/33600 [==============================] - 12s 367us/step - loss: 0.0339 - acc: 0.9905 - val_loss: 0.0330 - val_acc: 0.9923\n",
      "Epoch 20/50\n",
      "33600/33600 [==============================] - 12s 366us/step - loss: 0.0323 - acc: 0.9913 - val_loss: 0.0385 - val_acc: 0.9914\n",
      "Epoch 21/50\n",
      "33600/33600 [==============================] - 12s 365us/step - loss: 0.0300 - acc: 0.9918 - val_loss: 0.0314 - val_acc: 0.9918\n",
      "Epoch 22/50\n",
      "33600/33600 [==============================] - 12s 366us/step - loss: 0.0299 - acc: 0.9913 - val_loss: 0.0346 - val_acc: 0.9919\n",
      "Epoch 23/50\n",
      "33600/33600 [==============================] - 12s 366us/step - loss: 0.0267 - acc: 0.9924 - val_loss: 0.0363 - val_acc: 0.9918\n",
      "Epoch 24/50\n",
      "33600/33600 [==============================] - 12s 366us/step - loss: 0.0245 - acc: 0.9935 - val_loss: 0.0350 - val_acc: 0.9923\n",
      "Epoch 25/50\n",
      "33600/33600 [==============================] - 12s 366us/step - loss: 0.0239 - acc: 0.9932 - val_loss: 0.0379 - val_acc: 0.9906\n",
      "Epoch 26/50\n",
      "33600/33600 [==============================] - 12s 365us/step - loss: 0.0209 - acc: 0.9937 - val_loss: 0.0386 - val_acc: 0.9915\n",
      "Epoch 27/50\n",
      "33600/33600 [==============================] - 12s 372us/step - loss: 0.0211 - acc: 0.9941 - val_loss: 0.0352 - val_acc: 0.9921\n",
      "Epoch 28/50\n",
      "33600/33600 [==============================] - 12s 361us/step - loss: 0.0211 - acc: 0.9939 - val_loss: 0.0345 - val_acc: 0.9914\n",
      "Epoch 29/50\n",
      "33600/33600 [==============================] - 12s 361us/step - loss: 0.0195 - acc: 0.9948 - val_loss: 0.0407 - val_acc: 0.9920\n",
      "Epoch 30/50\n",
      "33600/33600 [==============================] - 12s 354us/step - loss: 0.0182 - acc: 0.9947 - val_loss: 0.0363 - val_acc: 0.9929\n",
      "Epoch 31/50\n",
      "33600/33600 [==============================] - 12s 354us/step - loss: 0.0175 - acc: 0.9951 - val_loss: 0.0362 - val_acc: 0.9927\n",
      "Epoch 32/50\n",
      "33600/33600 [==============================] - 12s 353us/step - loss: 0.0183 - acc: 0.9951 - val_loss: 0.0358 - val_acc: 0.9931\n",
      "Epoch 33/50\n",
      "33600/33600 [==============================] - 12s 354us/step - loss: 0.0170 - acc: 0.9951 - val_loss: 0.0399 - val_acc: 0.9918\n",
      "Epoch 34/50\n",
      "33600/33600 [==============================] - 12s 352us/step - loss: 0.0140 - acc: 0.9960 - val_loss: 0.0393 - val_acc: 0.9914\n",
      "Epoch 35/50\n",
      "33600/33600 [==============================] - 12s 359us/step - loss: 0.0159 - acc: 0.9951 - val_loss: 0.0401 - val_acc: 0.9926\n",
      "Epoch 36/50\n",
      "33600/33600 [==============================] - 12s 352us/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.0463 - val_acc: 0.9910\n",
      "Epoch 37/50\n",
      "33600/33600 [==============================] - 12s 351us/step - loss: 0.0138 - acc: 0.9960 - val_loss: 0.0486 - val_acc: 0.9923\n",
      "Epoch 38/50\n",
      "33600/33600 [==============================] - 12s 351us/step - loss: 0.0126 - acc: 0.9967 - val_loss: 0.0431 - val_acc: 0.9918\n",
      "Epoch 39/50\n",
      "33600/33600 [==============================] - 12s 349us/step - loss: 0.0112 - acc: 0.9972 - val_loss: 0.0359 - val_acc: 0.9931\n",
      "Epoch 40/50\n",
      "33600/33600 [==============================] - 12s 352us/step - loss: 0.0128 - acc: 0.9967 - val_loss: 0.0386 - val_acc: 0.9931\n",
      "Epoch 41/50\n",
      "33600/33600 [==============================] - 12s 351us/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.0387 - val_acc: 0.9931\n",
      "Epoch 42/50\n",
      "33600/33600 [==============================] - 12s 349us/step - loss: 0.0122 - acc: 0.9965 - val_loss: 0.0373 - val_acc: 0.9924\n",
      "Epoch 43/50\n",
      "33600/33600 [==============================] - 12s 354us/step - loss: 0.0112 - acc: 0.9970 - val_loss: 0.0365 - val_acc: 0.9924\n",
      "Epoch 44/50\n",
      "33600/33600 [==============================] - 12s 351us/step - loss: 0.0112 - acc: 0.9969 - val_loss: 0.0355 - val_acc: 0.9926\n",
      "Epoch 45/50\n",
      "33600/33600 [==============================] - 12s 348us/step - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0382 - val_acc: 0.9930\n",
      "Epoch 46/50\n",
      "33600/33600 [==============================] - 12s 350us/step - loss: 0.0105 - acc: 0.9971 - val_loss: 0.0458 - val_acc: 0.9921\n",
      "Epoch 47/50\n",
      "33600/33600 [==============================] - 12s 349us/step - loss: 0.0107 - acc: 0.9968 - val_loss: 0.0403 - val_acc: 0.9927\n",
      "Epoch 48/50\n",
      "33600/33600 [==============================] - 12s 349us/step - loss: 0.0097 - acc: 0.9972 - val_loss: 0.0413 - val_acc: 0.9921\n",
      "Epoch 49/50\n",
      "33600/33600 [==============================] - 12s 351us/step - loss: 0.0088 - acc: 0.9970 - val_loss: 0.0411 - val_acc: 0.9921\n",
      "Epoch 50/50\n",
      "33600/33600 [==============================] - 12s 351us/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.0416 - val_acc: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6526b2ec50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 牛逼的Sequential类可以让我们灵活地插入不同的神经网络层\n",
    "model = Sequential()\n",
    "\n",
    "# 加上一个2D卷积层， 32个输出（也就是卷积通道），激活函数选用relu，\n",
    "# 卷积核的窗口选用3*3像素窗口\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# 池化层是2*2像素的\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 对于池化层的输出，采用0.35概率的Dropout\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# 池化层是2*2像素的\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 对于池化层的输出，采用0.35概率的Dropout\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "# 展平所有像素，比如[28*28] -> [784]\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# 对所有像素使用全连接层，输出为128，激活函数选用relu\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# 对所有像素使用全连接层，输出为64，激活函数选用relu\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# 对输入采用0.5概率的Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# 对刚才Dropout的输出采用softmax激活函数，得到最后结果0-9\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=64, verbose=1, validation_data=(x_valid, y_valid))\n",
    "\n",
    "# loss: 0.0293 - acc: 0.9915 - val_loss: 0.0323 - val_acc: 0.9925\n",
    "# LB -> 99.14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# predict results\n",
    "results = model.predict(x_test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "submit_df= pd.read_csv('../input/sample_submission.csv')\n",
    "submit_df.Label = results\n",
    "filename = \"../sub/{}.scv\".format(datetime.now().strftime('%Y%m%d_%H_%M'))\n",
    "submit_df.to_csv(filename,index=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}